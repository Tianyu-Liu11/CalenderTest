{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.14.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (2.6.4)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai \n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the OPENAI_KEY into \".env\" file, and *** AND .env TO YOUR .gitignore FILE. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For normal use GPT-4 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = f\"\"\"\n",
    "    I use the exec() funciton to run a python script. The code is:\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "\n",
    "    def query(calendar_data):\n",
    "        today = pd.to_datetime('2024-03-12')\n",
    "        calendar_data['start'] = pd.to_datetime(calendar_data['start'])\n",
    "        calendar_data['end'] = pd.to_datetime(calendar_data['end'])\n",
    "        today_events = calendar_data[(calendar_data['start'].dt.date == today) | (calendar_data['end'].dt.date == today)]\n",
    "        return len(today_events)\n",
    "\n",
    "    answer = query(calendar_data)\n",
    "    ```\n",
    "    \n",
    "    I use the following code to run the exec() function\n",
    "    ```python\n",
    "    exec(python_code_list[0])\n",
    "    ```\n",
    "    But i get error \"name 'pd' is not defined\". name 'calendar_data' is not defined and 'answer' not exists\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = f\"\"\"\n",
    "    Explain to how to use the exec() function as details as you can, including passing global parameters, local parameters and pacaages\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `exec()` function is a built-in function in Python that supports the dynamic execution of Python programming code. It accepts a block of code, a Python program as a string, and executes it within the scope where it was called.\n",
      "\n",
      "The basic syntax of exec() function is as follows:\n",
      "\n",
      "```python\n",
      "exec(object, globals, locals)\n",
      "```\n",
      "\n",
      "- `object`: Required. It must be either a string or code object. If it is a string, the string is parsed as a suite of Python statements which is then executed. If it is a code object, it is simply executed.\n",
      "\n",
      "- `globals`: Optional. It must be a dictionary represents global parameters. The modifications to the global namespace for the code such as adding a new global variable and reassigning the values of existing ones persist after the exec() function completes.\n",
      "\n",
      "- `locals`: Optional. It is a dictionary that represents local parameters. Its default value is a dictionary representing the current local symbol table.\n",
      "\n",
      "Here is an example of usage:\n",
      "\n",
      "```python\n",
      "code_string = \"\"\"\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "\"\"\"\n",
      "exec(code_string)\n",
      "print(add(3, 4))  # It will output: 7\n",
      "```\n",
      "\n",
      "In this example, a piece of Python code is passed to the exec() function as a string. After the exec() function is executed, function `add()` becomes available.\n",
      "\n",
      "`exec()` can be also used with globals and locals parameters:\n",
      "\n",
      "```python\n",
      "global_dict = {}\n",
      "local_dict = {}\n",
      "exec('global_val = 1', global_dict, local_dict)\n",
      "exec('local_val = 2', global_dict, local_dict)\n",
      "print(global_dict)\n",
      "print(local_dict)\n",
      "```\n",
      "\n",
      "In order to use the exec function with packages you can import a module and then using it inside a string code as follows:\n",
      "\n",
      "```python\n",
      "code_str = '''\n",
      "import math\n",
      "def sqrt(num):\n",
      "    return math.sqrt(num) \n",
      "'''\n",
      "exec(code_str)\n",
      "print(sqrt(4))   # Prints: 2.0\n",
      "```\n",
      "\n",
      "In this example, the `math` package is being used inside the string code after importing it.\n",
      "\n",
      "Note: Since exec() supports dynamic execution of Python code, it can be a potential security risk if you are executing code from untrusted sources.\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"gpt-4\"\n",
    "# MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\":PROMPT,\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL,\n",
    ")\n",
    "\n",
    "# verify the output\n",
    "generated_text = chat_completion.choices[0].message.content\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt for calendar questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"question\": \"What is the status and summary of the event with ID 12345?\",\n",
      "\"answer\": \"\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"question\": \"How many attendees are there for the meeting with ID 23456?\",\n",
      "\"answer\": \"\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"question\": \"What is the duration of the event with ID 34567?\",\n",
      "\"answer\": \"\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"question\": \"When does the event with ID 45678 start and end?\",\n",
      "\"answer\": \"\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"question\": \"What is the longest event on my calendar?\",\n",
      "\"answer\": \"\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"question\": \"Who are the attendees for the event with ID 56789?\",\n",
      "\"answer\": \"\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"question\": \"Find events with the status 'Cancelled'?\",\n",
      "\"answer\": \"\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"question\": \"What events are scheduled to start tomorrow?\",\n",
      "\"answer\": \"\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"question\": \"List events with duration longer than 2 hours?\",\n",
      "\"answer\": \"\"\n",
      "}\n",
      "\n",
      "{\n",
      "\"question\": \"How many events do I have scheduled for today?\",\n",
      "\"answer\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# prompt = \"\"\" You will be provided with a dataframe \"calendar_data\". \"calendar_data\" consists of 7 columns, which can be represented as calendar_Data(ID, status, summary, start, end , duration, attendees).\n",
    "# Input dataset: ID is the meeting ID; start is the meeting start time; end is the meeting end time; duration is how long the meeting last; attendees is who will attend the meeting\n",
    "\n",
    "# Write 10 different questions to operate dataframe. For example:\n",
    "\n",
    "# \"create meeting with Natalia Shreve tomorrow at 10 am\",\n",
    "# \"remove tomorrow's meeting at 10 am\",\n",
    "# \"reschedule recurrent daily Meeting with Bob to 5 pm\".\n",
    "# \"Do I have meeting today\"\n",
    "# \"\"\"\n",
    "\n",
    "prompt = f\"\"\" You are provided a ```dataframe(ID, status, summary, start, end , duration, attendees)```. This dataframe includes all you calenders.\n",
    "Your task is generate questions to query this dataframe. Output a json object that contains the following keys: question, answer. Fill the answer key blank.\n",
    "\n",
    "Output JSON: <json with question and answer>\n",
    "\"\"\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL,\n",
    ")\n",
    "\n",
    "# verify the output\n",
    "generated_text = chat_completion.choices[0].message.content\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert output into json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt for generting meeting date with format YYYY-MM-DD hh:mm:ss-00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. {Start: 2024-02-06 09:00:00-00:00, End: 2024-02-06 10:30:00-00:00}\n",
      "2. {Start: 2024-02-06 14:00:00-00:00, End: 2024-02-06 15:30:00-00:00}\n",
      "3. {Start: 2024-02-13 09:00:00-00:00, End: 2024-02-13 10:30:00-00:00}\n",
      "4. {Start: 2024-02-13 14:00:00-00:00, End: 2024-02-13 15:30:00-00:00}\n",
      "5. {Start: 2024-02-20 09:30:00-00:00, End: 2024-02-20 11:00:00-00:00}\n",
      "6. {Start: 2024-02-20 14:00:00-00:00, End: 2024-02-20 15:30:00-00:00}\n",
      "7. {Start: 2024-02-27 09:00:00-00:00, End: 2024-02-27 10:30:00-00:00}\n",
      "8. {Start: 2024-02-27 14:00:00-00:00, End: 2024-02-27 15:30:00-00:00}\n",
      "9. {Start: 2024-03-05 09:30:00-00:00, End: 2024-03-05 11:00:00-00:00}\n",
      "10. {Start: 2024-03-05 14:00:00-00:00, End: 2024-03-05 15:30:00-00:00}\n",
      "11. {Start: 2024-03-12 09:00:00-00:00, End: 2024-03-12 10:30:00-00:00}\n",
      "12. {Start: 2024-03-12 14:00:00-00:00, End: 2024-03-12 15:30:00-00:00}\n",
      "13. {Start: 2024-03-19 09:30:00-00:00, End: 2024-03-19 11:00:00-00:00}\n",
      "14. {Start: 2024-03-19 14:00:00-00:00, End: 2024-03-19 15:30:00-00:00}\n",
      "15. {Start: 2024-03-26 09:00:00-00:00, End: 2024-03-26 10:30:00-00:00}\n",
      "16. {Start: 2024-03-26 14:00:00-00:00, End: 2024-03-26 15:30:00-00:00}\n",
      "17. {Start: 2024-04-02 09:30:00-00:00, End: 2024-04-02 11:00:00-00:00}\n",
      "18. {Start: 2024-04-02 14:00:00-00:00, End: 2024-04-02 15:30:00-00:00}\n",
      "19. {Start: 2024-02-10 15:00:00-00:00, End: 2024-02-10 17:00:00-00:00}\n",
      "20. {Start: 2024-03-10 15:00:00-00:00, End: 2024-03-10 17:00:00-00:00}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\" Help me generate 20 meeting date, including start date and end date. \n",
    "Date format: YYYY-MM-DD hh:mm:ss-00:00\n",
    "\n",
    "Limitations:\n",
    "The meeting usually lasts 30 minutes to 2 hours;\n",
    "The meeting should start from 2024-02-03 to 2024-04-05\n",
    "Every tuesday, there are at least 2 meetings\n",
    "\n",
    "\n",
    "Here is the example: \n",
    "{Start: 2024-03-24 10:00:00-00:00\n",
    " End:   2024-03-24 10:45:00-00:00   \n",
    "}\n",
    "\n",
    "Results:\n",
    "\"\"\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL,\n",
    ")\n",
    "\n",
    "# verify the output\n",
    "generated_text = chat_completion.choices[0].message.content\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt for generting meeting topic and attendees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, let's generate these 10 meetings:\n",
      "\n",
      "1. Meeting Topic: Project Kickoff \n",
      "walter@ninjatech.ai(accepted)\n",
      " arash@ninjatech.ai(accepted)\n",
      "\n",
      "2. Meeting Topic: Agile Development Workflow\n",
      "walter@ninjatech.ai(accepted)\n",
      " alice@ninjatech.ai(accepted)\n",
      "\n",
      "3. Meeting Topic: Code Review \n",
      "walter@ninjatech.ai(accepted)\n",
      " bob@ninjatech.ai(accepted)\n",
      "\n",
      "4. Meeting Topic: Research Planning\n",
      "walter@ninjatech.ai(accepted)\n",
      " carrie@ninjatech.ai(accepted)\n",
      "\n",
      "5. Meeting Topic: Debugging And Error Handling \n",
      "walter@ninjatech.ai(accepted)\n",
      " david@ninjatech.ai(accepted)\n",
      "\n",
      "6. Meeting Topic: Weekly Progress Review\n",
      "walter@ninjatech.ai(accepted)\n",
      " arash@ninjatech.ai(needsAction)\n",
      "\n",
      "7. Meeting Topic: Database Architecture \n",
      "walter@ninjatech.ai(accepted)\n",
      " alice@ninjatech.ai(needsAction)\n",
      "\n",
      "8. Meeting Topic: Security Best Practices \n",
      "walter@ninjatech.ai(accepted)\n",
      " bob@ninjatech.ai(accepted)\n",
      "\n",
      "9. Meeting Topic: UI/UX Design \n",
      "walter@ninjatech.ai(accepted)\n",
      " carrie@ninjatech.ai(rejected)\n",
      "\n",
      "10. Meeting Topic: API Integration \n",
      "walter@ninjatech.ai(accepted)\n",
      " david@ninjatech.ai(needsAction)\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\" You are walter, a new software engineer employee of NinjaTech AI. You have many meetings with team members, \n",
    "for example  meeting with the team leader Arash about the project progress and research plan. You have 4 team members: Alice, Bob, Carrie, David. You have regular meeting every Monday about project progress.\n",
    "You also need to talk to them about research issues. \n",
    "Help me generate all your 10 meetings, in terms of meeting topic and attendees. \n",
    "Meeting attendees are their ninjatech emails, for exampole ${name}$@ninjatech.ai(${status}$).  \n",
    "${name}$ is their name and ${status}$ denotes if they accepted the meeting invitation. ${status}$ could be accepted, needsAction, and rejected.\n",
    "Each meeting usually include 2 people but no more than the all people in this company.\n",
    "The output format is ${name}$@ninjatech.ai(${status}$)\\n ${name}$@ninjatech.ai(${status}$)\n",
    "Here is the example: \n",
    "\"meeting Topic: \n",
    "temp-testing@ninjatech.ai(accepted)\\n yevhenia.spiridonova@ninjatech.ai(needsAction)\"\n",
    "\"\"\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL,\n",
    ")\n",
    "\n",
    "# verify the output\n",
    "generated_text = chat_completion.choices[0].message.content\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\" You are walter, a new software engineer employee of NinjaTech AI. You have many meetings team members, \n",
    "for example meet with organizer Natalia about the job application, interview process, contract discussion and meeting with the team leader Arash. \n",
    "Help me generate all your 10 meetings, in terms of meeting topic and attendees. \n",
    "Meeting attendees are their ninjatech emails, for exampole ${name}$@ninjatech.ai(${status}$).  \n",
    "${name}$ is their name and ${status}$ denotes if they accepted the meeting invitation. ${status}$ could be accepted, needsAction, and rejected.\n",
    "Each meeting usually include 2 people but no more than the all people in this company.\n",
    "The output format is ${name}$@ninjatech.ai(${status}$)\\n ${name}$@ninjatech.ai(${status}$)\n",
    "Here is the example: \n",
    "\"meeting Topic: \n",
    "temp-testing@ninjatech.ai(accepted)\\n yevhenia.spiridonova@ninjatech.ai(needsAction)\"\n",
    "\"\"\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL,\n",
    ")\n",
    "\n",
    "# verify the output\n",
    "generated_text = chat_completion.choices[0].message.content\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt for generating attendees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, you can use the `json` module provided by Python to achieve this. Below is a simple function that converts a multiline string into a .json format:\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "def convert_to_json(multiline_string):\n",
      "    # Split the multiline string into a list of lines\n",
      "    lines = multiline_string.split(\"\\n\")\n",
      "    \n",
      "    # Convert the list into a json string\n",
      "    json_string = json.dumps(lines)\n",
      "    \n",
      "    return json_string\n",
      "\n",
      "# Test the function\n",
      "multiline_string = \"\"\"\n",
      "This is line 1\n",
      "This is line 2\n",
      "This is line 3\n",
      "\"\"\"\n",
      "\n",
      "print(convert_to_json(multiline_string))\n",
      "```\n",
      "\n",
      "Please note that this code would convert each line in the multiline string as a separate item of an array in the resulting .json.\n",
      "\n",
      "If your multiline string is actually representing a .json, you don't need to split your string line by line. You can directly load it into .json as shown below:\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "def convert_to_json(multiline_json_string):\n",
      "    try:\n",
      "        json_data = json.loads(multiline_json_string)\n",
      "        return json_data\n",
      "    except json.JSONDecodeError as e:\n",
      "        return str(e)\n",
      "\n",
      "multiline_json_string = \"\"\"\n",
      "{\n",
      "    \"key1\": \"value1\",\n",
      "    \"key2\": \"value2\",\n",
      "    \"key3\": \"value3\"\n",
      "}\n",
      "\"\"\"\n",
      "print(convert_to_json(multiline_json_string))\n",
      "```\n",
      "\n",
      "Please replace the test data with your real data.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\" You are a meeting organzer. Help me generate 7 meeting start date and end data for this week. Today is 2024-03-27 Wednesday.\n",
    "The meeting may be in several days age, may be in today, and may be several days late. For each day, there are no meeting, 1 meeting or 2 meeting.\n",
    "The meeting usually lasts for 10 minutes to 2 hours.\n",
    "Date format: YYYY-MM-DD hh:mm:ss-00:00. The meeting should be in time order\n",
    "Here is the example: \n",
    "{Start date: 2024-03-27 12:00:00-00:00\n",
    " end date: 2024-03-27 12:30:00-00:00\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL,\n",
    ")\n",
    "\n",
    "# verify the output\n",
    "generated_text = chat_completion.choices[0].message.content\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the ***gpt-3.5-turbo***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an instance of OpenAI's GPT-3 model.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    # {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    # {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "    {\"role\": \"user\", \"content\": \"Are you GPT4 or GPT3.5?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
