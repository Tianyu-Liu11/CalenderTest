{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calendar_data(DATA_PATH):\n",
    "    return pd.read_csv(DATA_PATH + \"calendar_data.csv\")\n",
    "\n",
    "\n",
    "def get_question(DATA_PATH):\n",
    "    with open(DATA_PATH + \"question.json\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    return json_data\n",
    "    \n",
    "\n",
    "    \n",
    "def get_prompt(question, examples):\n",
    "    \n",
    "    task = f\"\"\"{question}\n",
    "    \"\"\"\n",
    "\n",
    "    PROMPT = f\"\"\"Answer the following question based on the JSON file with agenda from Google Calendar.\\n Question: {task}'\n",
    "                \\n\\nJSON file with agenda:\\n{examples}. Today's date is '2024-04-02 09:02:30' with date format '%Y-%m-%d %H:%M:%S'\"\"\"\n",
    "                        \n",
    "    return PROMPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_completion(MODEL, PROMPT):\n",
    "\n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\":PROMPT,\n",
    "            }\n",
    "        ],\n",
    "        model=MODEL,\n",
    "    )\n",
    "\n",
    "    # verify the output\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline test for GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = \"../data/\"\n",
    "MODEL = \"gpt-4\"\n",
    "# MODEL = \"ft:gpt-3.5-turbo-1106:ninjatech-ai-dev::8sQyzUKb\"\n",
    "print(MODEL)\n",
    "    \n",
    "result = {'success': 0, 'wrong_answer': 0, 'error': 0}\n",
    "question_answer_summary = {'question': '',\n",
    "                            'true_answer':'', \n",
    "                            'generated_answer': ''\n",
    "                            }\n",
    "result_list = []\n",
    "    \n",
    "calendar_data = get_calendar_data(DATA_PATH=DATA_PATH)\n",
    "queston_answer_pairs = get_question(DATA_PATH=DATA_PATH)\n",
    "calendar_data_JSON = calendar_data.to_json() \n",
    "    \n",
    "ground_true = []\n",
    "for i in range(5):\n",
    "        \n",
    "    result = {'success': 0, 'wrong_answer': 0, 'error': 0}\n",
    "        \n",
    "    for q_a_pair in queston_answer_pairs:\n",
    "\n",
    "        # print(f\"\"\"Question: {q_a_pair['question']}\\n True answer: {q_a_pair['answer']}\"\"\")\n",
    "            \n",
    "        PROMPT = get_prompt(q_a_pair['question'], calendar_data_JSON)\n",
    "            \n",
    "        llm_reply = get_completion(MODEL, PROMPT)\n",
    "        # print(f\"\"\"The answer of LLM: {llm_reply}\"\"\")\n",
    "            \n",
    "        if str(q_a_pair['answer']) in llm_reply.lower():\n",
    "            result['success'] += 1\n",
    "        else:\n",
    "            result['wrong_answer'] += 1\n",
    "            \n",
    "        # result analysis\n",
    "        question_answer_summary['question'] = q_a_pair['question']\n",
    "        question_answer_summary['true_answer'] = q_a_pair['answer']\n",
    "        question_answer_summary['generated_code'] = llm_reply\n",
    "    print(result)\n",
    "    result_list.append(result.copy())\n",
    "print(result_list)\n",
    "\n",
    "# with open('baseline_' + f\"\"\"{MODEL}\"\"\" + '_results.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(result_list, f, indent=4) \n",
    "\n",
    "print('End')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline - test the GPT3.5 finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-1106:ninjatech-ai-dev::8sQyzUKb\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "DATA_PATH = \"../data/\"\n",
    "# MODEL = \"gpt-4\"\n",
    "MODEL = \"ft:gpt-3.5-turbo-1106:ninjatech-ai-dev::8sQyzUKb\"\n",
    "print(MODEL)\n",
    "\n",
    "calendar_data = get_calendar_data(DATA_PATH=DATA_PATH)\n",
    "queston_answer_pairs = get_question(DATA_PATH=DATA_PATH)\n",
    "calendar_data_JSON = calendar_data.to_json() \n",
    "\n",
    "# convert the start and end time into datetime format (%Y-%m-%d %H:%M:%S)\n",
    "def convert_date(calendar_data):   \n",
    "    # Convert 'start' and 'end' columns to datetime objects\n",
    "    calendar_data['start'] = pd.to_datetime(calendar_data['start'])\n",
    "    calendar_data['end']   = pd.to_datetime(calendar_data['end'])\n",
    "\n",
    "    # Format 'start' and 'end' columns into the desired string format\n",
    "    calendar_data['start'] = calendar_data['start'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    calendar_data['end']   = calendar_data['end'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    return calendar_data\n",
    "calendar_data = convert_date(calendar_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recurrent': False, 'summary': 'Team Introduction', 'description': None, 'attendees': 'walter@ninjatech.ai(accepted)\\\\n arash@ninjatech.ai(accepted)', 'original_timezone': <DstTzInfo 'Australia/Sydney' LMT+10:05:00 STD>, 'start': '2024-02-15 09:00:00', 'end': '2024-02-15 09:30:00', 'duration': 1800, 'weekday': 'Thursday'}\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "\n",
    "def convert_dataframe_to_agenda(calendar_data):\n",
    "    agenda_type = {}\n",
    "    agenda_type[\"recurrent\"] = False\n",
    "    agenda_type[\"summary\"] = calendar_data[\"summary\"]\n",
    "    agenda_type[\"description\"] = None\n",
    "    agenda_type[\"attendees\"] = calendar_data[\"attendees\"]\n",
    "    agenda_type[\"original_timezone\"] = pytz.timezone('Australia/Sydney')\n",
    "    agenda_type[\"start\"] = calendar_data[\"start\"]\n",
    "    agenda_type[\"end\"] = calendar_data[\"end\"]\n",
    "    agenda_type[\"duration\"] = calendar_data[\"duration\"]\n",
    "    \n",
    "    weekdays = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    weekday = weekdays[pd.to_datetime(calendar_data[\"start\"], format='%Y-%m-%d %H:%M:%S').weekday()]\n",
    "    \n",
    "    agenda_type[\"weekday\"] = weekday\n",
    "    \n",
    "    return agenda_type\n",
    "\n",
    "calendar_data_to_agenda = []\n",
    "for i in range(len(calendar_data)):\n",
    "    calendar_data_to_agenda.append(convert_dataframe_to_agenda(calendar_data.iloc[i]))\n",
    "print(calendar_data_to_agenda[2])\n",
    "\n",
    "def get_vinalla_prompt(question, examples):\n",
    "    \n",
    "    task = f\"\"\"{question}\n",
    "    \"\"\"\n",
    "\n",
    "    PROMPT = f\"\"\"Answer the following question based on the JSON file with agenda from Google Calendar.\\n Question: {task}'\n",
    "                \\n\\nJSON file with agenda:\\n{examples}.\"\"\"\n",
    "                        \n",
    "    return PROMPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': 8, 'wrong_answer': 38, 'error': 0}\n",
      "{'success': 7, 'wrong_answer': 39, 'error': 0}\n",
      "{'success': 4, 'wrong_answer': 42, 'error': 0}\n",
      "{'success': 10, 'wrong_answer': 36, 'error': 0}\n",
      "{'success': 8, 'wrong_answer': 38, 'error': 0}\n",
      "[{'success': 8, 'wrong_answer': 38, 'error': 0}, {'success': 7, 'wrong_answer': 39, 'error': 0}, {'success': 4, 'wrong_answer': 42, 'error': 0}, {'success': 10, 'wrong_answer': 36, 'error': 0}, {'success': 8, 'wrong_answer': 38, 'error': 0}]\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = {'success': 0, 'wrong_answer': 0, 'error': 0}\n",
    "question_answer_summary = {'question': '',\n",
    "                            'true_answer':'', \n",
    "                            'generated_answer': ''\n",
    "                            }\n",
    "result_list = []\n",
    "    \n",
    "ground_true = []\n",
    "for i in range(5):\n",
    "        \n",
    "    result = {'success': 0, 'wrong_answer': 0, 'error': 0}\n",
    "        \n",
    "    for q_a_pair in queston_answer_pairs:\n",
    "\n",
    "        # print(f\"\"\"Question: {q_a_pair['question']}\\n True answer: {q_a_pair['answer']}\"\"\")\n",
    "            \n",
    "        PROMPT = get_vinalla_prompt(q_a_pair['question'], calendar_data_to_agenda)\n",
    "            \n",
    "        llm_reply = get_completion(MODEL, PROMPT)\n",
    "        # print(f\"\"\"The answer of LLM: {llm_reply}\"\"\")\n",
    "            \n",
    "        if str(q_a_pair['answer']) in llm_reply.lower():\n",
    "            result['success'] += 1\n",
    "        else:\n",
    "            result['wrong_answer'] += 1\n",
    "            \n",
    "        # result analysis\n",
    "        question_answer_summary['question'] = q_a_pair['question']\n",
    "        question_answer_summary['true_answer'] = q_a_pair['answer']\n",
    "        question_answer_summary['generated_code'] = llm_reply\n",
    "    print(result)\n",
    "    result_list.append(result.copy())\n",
    "print(result_list)\n",
    "\n",
    "# with open('baseline_' + f\"\"\"{MODEL}\"\"\" + '_results.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(result_list, f, indent=4) \n",
    "\n",
    "print('End')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
